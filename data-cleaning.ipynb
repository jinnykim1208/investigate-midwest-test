{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb59728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38ffdc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine accidents\n",
    "                      \n",
    "accident_csv_files = sorted(glob.glob('data/accident/*.csv'))                  \n",
    "\n",
    "# Read and combine all chunks\n",
    "accident_schema = {\n",
    "      \"SUMMARY_NR\": pl.Utf8,\n",
    "      \"REPORT_ID\": pl.Utf8,\n",
    "      \"EVENT_DATE\": pl.Utf8,  \n",
    "      \"EVENT_TIME\": pl.Utf8,\n",
    "      'EVENT_DESC': pl.Utf8, \n",
    "      'EVENT_KEYWORD': pl.Utf8, \n",
    "      'CONST_END_USE': pl.Utf8, \n",
    "      'BUILD_STORIES': pl.Float64, \n",
    "      'NONBUILD_HT': pl.Float64, \n",
    "      'PROJECT_COST': pl.Utf8, \n",
    "      'PROJECT_TYPE': pl.Utf8, \n",
    "      'SIC_LIST': pl.Utf8, \n",
    "      'FATALITY': pl.Utf8, \n",
    "      'STATE_FLAG': pl.Utf8, \n",
    "      'ABSTRACT_TEXT': pl.Utf8, \n",
    "      'LOAD_DT': pl.Utf8}\n",
    "\n",
    "accident_combined = pl.concat([\n",
    "    pl.read_csv(file, schema_overrides=accident_schema, ignore_errors=True) for file in accident_csv_files\n",
    "]).with_columns(\n",
    "    pl.col('EVENT_DATE').str.strptime(pl.Datetime, format='%Y-%m-%d %H:%M:%S%z').dt.date()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca8014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine accident injury\n",
    "                      \n",
    "injuries_csv_files = sorted(glob.glob('data/accident_injury/*.csv'))                  \n",
    "\n",
    "# Read and combine all chunks\n",
    "injury_schema = {\n",
    "      \"SUMMARY_NR\": pl.Utf8,\n",
    "      \"REL_INSP_NR\": pl.Utf8,\n",
    "      \"AGE\": pl.Float64,  \n",
    "      \"SEX\": pl.Utf8,\n",
    "      'NATURE_OF_INJ': pl.Float64, \n",
    "      'PART_OF_BODY': pl.Float64, \n",
    "      'SRC_OF_INJURY': pl.Float64, \n",
    "      'EVENT_TYPE': pl.Float64, \n",
    "      'EVN_FACTOR': pl.Float64, \n",
    "      'HUM_FACTOR': pl.Float64, \n",
    "      'OCC_CODE': pl.Float64, \n",
    "      'DEGREE_OF_INJ': pl.Float64, \n",
    "      'TASK_ASSIGNED': pl.Float64, \n",
    "      'HAZSUB': pl.Utf8, \n",
    "      'CONST_OP': pl.Float64, \n",
    "      'CONST_OP_CAUSE': pl.Utf8,\n",
    "      'FAT_CAUSE': pl.Utf8,\n",
    "      'FALL_DISTANCE': pl.Float64,\n",
    "      'FALL_HT': pl.Float64,\n",
    "      'INJURY_LINE_NR': pl.Utf8,\n",
    "      'LOAD_DT': pl.Utf8}\n",
    "\n",
    "injury_combined = pl.concat([\n",
    "    pl.read_csv(file, schema_overrides=injury_schema, ignore_errors=True) for file in injuries_csv_files\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d6d0e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine inspection\n",
    "                      \n",
    "inspection_csv_files = sorted(glob.glob('data/inspection/*.csv'))                  \n",
    "\n",
    "# Read and combine all chunks\n",
    "inspection_schema = {\n",
    "      \"ACTIVITY_NR\": pl.Utf8,\n",
    "      \"REPORTING_ID\": pl.Utf8,\n",
    "      \"STATE_FLAG\": pl.Utf8,  \n",
    "      \"ESTAB_NAME\": pl.Utf8,\n",
    "      'SITE_ADDRESS': pl.Utf8, \n",
    "      'SITE_CITY': pl.Utf8, \n",
    "      'SITE_STATE': pl.Utf8, \n",
    "      'SITE_ZIP': pl.Utf8, \n",
    "      'OWNER_TYPE': pl.Utf8, \n",
    "      'OWNER_CODE': pl.Utf8, \n",
    "      'ADV_NOTICE': pl.Utf8, \n",
    "      'SAFETY_HLTH': pl.Utf8, \n",
    "      'SIC_CODE': pl.Utf8, \n",
    "      'NAICS_CODE': pl.Utf8, \n",
    "      'INSP_TYPE': pl.Utf8, \n",
    "      'INSP_SCOPE': pl.Utf8,\n",
    "      'WHY_NO_INSP': pl.Utf8,\n",
    "      'UNION_STATUS': pl.Utf8,\n",
    "      'SAFETY_MANUF': pl.Utf8,\n",
    "      'SAFETY_CONST': pl.Utf8,\n",
    "      'SAFETY_MARIT': pl.Utf8,\n",
    "      'HEALTH_MANUF': pl.Utf8,\n",
    "      'HEALTH_CONST': pl.Utf8,\n",
    "      'HEALTH_MARIT': pl.Utf8,\n",
    "      'MIGRANT': pl.Utf8,\n",
    "      'MAIL_STREET': pl.Utf8,\n",
    "      'MAIL_CITY': pl.Utf8,\n",
    "      'MAIL_STATE': pl.Utf8,\n",
    "      'MAIL_ZIP': pl.Utf8,\n",
    "      'HOST_EST_KEY': pl.Utf8,\n",
    "      'NR_IN_ESTAB': pl.Float64,\n",
    "      'OPEN_DATE': pl.Utf8,\n",
    "      'CASE_MOD_DATE': pl.Utf8,\n",
    "      'CLOSE_CONF_DATE': pl.Utf8,\n",
    "      'CLOSE_CASE_DATE': pl.Utf8,\n",
    "      'LOAD_DT': pl.Utf8,\n",
    "      }\n",
    "\n",
    "inspection_combined = pl.concat([\n",
    "    pl.read_csv(file, schema_overrides=inspection_schema, ignore_errors=True) for file in inspection_csv_files\n",
    "]).with_columns(\n",
    "    pl.col('OPEN_DATE').str.strptime(pl.Datetime, format='%Y-%m-%d %H:%M:%S%z').dt.date(),\n",
    ").with_columns(\n",
    "    pl.col(\"OPEN_DATE\").dt.year().alias(\"OPEN_YEAR\")\n",
    ").with_columns(\n",
    "    pl.when(pl.col(\"NR_IN_ESTAB\") <= 25)\n",
    "        .then(pl.lit(\"Very Small\"))\n",
    "    .when(pl.col(\"NR_IN_ESTAB\") <= 100)\n",
    "        .then(pl.lit(\"Small-Mid\"))\n",
    "    .when(pl.col(\"NR_IN_ESTAB\") <= 250)\n",
    "        .then(pl.lit(\"Mid-Large\"))\n",
    "    .when(pl.col(\"NR_IN_ESTAB\") > 250)\n",
    "        .then(pl.lit(\"Large\"))\n",
    "    .otherwise(pl.lit(None))\n",
    "    .alias(\"ESTAB_SIZE_FLAG\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd2f82df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine violations\n",
    "                      \n",
    "violation_csv_files = sorted(glob.glob('data/violation/*.csv'))                  \n",
    "\n",
    "# Read and combine all chunks\n",
    "violation_schema = {\n",
    "        'ACTIVITY_NR': pl.Utf8,\n",
    "        'CITATION_ID': pl.Utf8,\n",
    "        'DELETE_FLAG': pl.Utf8,\n",
    "        'STANDARD': pl.Utf8,\n",
    "        'VIOL_TYPE': pl.Utf8,\n",
    "        'ISSUANCE_DATE': pl.Utf8,\n",
    "        'ABATE_DATE': pl.Utf8,\n",
    "        'ABATE_COMPLETE': pl.Utf8,\n",
    "        'CURRENT_PENALTY': pl.Float64,\n",
    "        'INITIAL_PENALTY': pl.Float64,\n",
    "        'CONTEST_DATE': pl.Utf8,\n",
    "        'FINAL_ORDER_DATE': pl.Utf8,\n",
    "        'NR_INSTANCES': pl.Float64,\n",
    "        'NR_EXPOSED': pl.Float64,\n",
    "        'REC': pl.Utf8,\n",
    "        'GRAVITY': pl.Float64,\n",
    "        'EMPHASIS': pl.Utf8,\n",
    "        'HAZCAT': pl.Utf8,\n",
    "        'FTA_INSP_NR': pl.Utf8,\n",
    "        'FTA_ISSUANCE_DATE': pl.Utf8,\n",
    "        'FTA_PENALTY': pl.Float64,\n",
    "        'FTA_CONTEST_DATE': pl.Utf8,\n",
    "        'FTA_FINAL_ORDER_DATE': pl.Utf8,\n",
    "        'HAZSUB1': pl.Utf8,\n",
    "        'HAZSUB2': pl.Utf8,\n",
    "        'HAZSUB3': pl.Utf8,\n",
    "        'HAZSUB4': pl.Utf8,\n",
    "        'HAZSUB5': pl.Utf8,\n",
    "        'LOAD_DT': pl.Utf8\n",
    "      }\n",
    "\n",
    "violation_combined = pl.concat([\n",
    "    pl.read_csv(file, schema_overrides=violation_schema, ignore_errors=True) for file in violation_csv_files\n",
    "]).with_columns(\n",
    "    pl.col('ISSUANCE_DATE').str.strptime(pl.Datetime, format='%Y-%m-%d %H:%M:%S%z').dt.date(),\n",
    "    pl.col('ABATE_DATE').str.strptime(pl.Datetime, format='%Y-%m-%d %H:%M:%S%z').dt.date(),\n",
    "    pl.col('CONTEST_DATE').str.strptime(pl.Datetime, format='%Y-%m-%d %H:%M:%S%z').dt.date(),\n",
    "    pl.col('FINAL_ORDER_DATE').str.strptime(pl.Datetime, format='%Y-%m-%d %H:%M:%S%z').dt.date(),\n",
    "    pl.col('FTA_ISSUANCE_DATE').str.strptime(pl.Datetime, format='%Y-%m-%d %H:%M:%S%z').dt.date(),\n",
    "    pl.col('FTA_CONTEST_DATE').str.strptime(pl.Datetime, format='%Y-%m-%d %H:%M:%S%z').dt.date(),\n",
    "    pl.col('FTA_FINAL_ORDER_DATE').str.strptime(pl.Datetime, format='%Y-%m-%d %H:%M:%S%z').dt.date(),\n",
    ").with_columns(\n",
    "    pl.when(pl.col(\"INITIAL_PENALTY\") > 0)\n",
    "    .then(\n",
    "            ( (pl.col(\"CURRENT_PENALTY\") - pl.col(\"INITIAL_PENALTY\")) / pl.col(\"INITIAL_PENALTY\") ).alias(\"PENALTY_PCT_REDUCTION\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92d2e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine accident abstracts\n",
    "                      \n",
    "abstract_csv_files = sorted(glob.glob('data/accident_abstract/*.csv'))                  \n",
    "\n",
    "# Read and combine all chunks\n",
    "abstract_schema = {\n",
    "        'SUMMARY_NR': pl.Utf8,\n",
    "        'LINE_NR': pl.Utf8,\n",
    "        'ABSTRACT_TEXT': pl.Utf8,\n",
    "        'LOAD_DT' :pl.Utf8\n",
    "      }\n",
    "\n",
    "abstract_combined = pl.concat([\n",
    "    pl.read_csv(file, schema_overrides=abstract_schema, ignore_errors=True) for file in abstract_csv_files\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa997f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine citation abstracts\n",
    "                      \n",
    "citation_csv_files = sorted(glob.glob('data/citation/*.csv'))                  \n",
    "\n",
    "# Read and combine all chunks\n",
    "citation_schema = {\n",
    "        'ACTIVITY_NR': pl.Utf8,\n",
    "        'CITATION_ID': pl.Utf8,\n",
    "        'LINE_NR': pl.Utf8,\n",
    "        'LINE_TEXT': pl.Utf8,\n",
    "        'LOAD_DT' :pl.Utf8\n",
    "      }\n",
    "\n",
    "citation_combined = pl.concat([\n",
    "    pl.read_csv(file, schema_overrides=citation_schema, ignore_errors=True) for file in citation_csv_files\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd54eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_combined.write_parquet(\"data/clean/accidents.parquet\")\n",
    "injury_combined.write_parquet(\"data/clean/injuries.parquet\")\n",
    "inspection_combined.write_parquet(\"data/clean/inspections.parquet\")\n",
    "violation_combined.write_parquet(\"data/clean/violations.parquet\")\n",
    "abstract_combined.write_parquet(\"data/clean/abstracts.parquet\")\n",
    "citation_combined.write_parquet(\"data/clean/citations.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
